---
title: "Lab_3_SVM"
author: "Elsie Horne"
date: "8 December 2017"
output: html_document
---

# Lab 3: Support Vector Mahcines

# 1. Spam filtering

Load tidyverse
```{r load_packages, message = FALSE}
library(tidyverse)
```

## ========== Question 1.1 ==========

**Load spambase_binary.csv, display the number of instances and attributes and the first 5 samples. Remember that the attributes have been binarised. The instances have also been shuffled (i.e. their order has been randomised)**

``` {r q1.1}
spambase_binary <- read.csv(file = "spambase_binary.csv") # need to sort out the encoding here for the special characters
spambase_binary <- as_tibble(spambase_binary)
dim(spambase_binary)[1] # instances
dim(spambase_binary)[2] # attributes
head(spambase_binary, 5)
```

## ========== Question 1.2 ==========
**We are going to use hold-out validation to evaluate our models below. Split the dataset into training and testing subsets. Use 90% of the data for training and the remaining 10% for testing.**

**If you want to be able to reproduce your results exactly, what argument must you remember to set?**
Must set a seed.

``` {r q1.2}
set.seed(123) # set seed so that we produce the same train/test sets if analysis repeated

spambase_binary <- spambase_binary %>% # create variables to split to train and test set
  mutate(train = runif(nrow(spambase_binary)), rank = rank(train)) 

spam_test  <- spambase_binary %>% # create test set
  filter(rank<=0.1*nrow(spambase_binary)) %>%
  select(-train, - rank)

spam_train <- spambase_binary %>% # create train set
  filter(rank>0.1*nrow(spambase_binary)) %>%
  select(-train, - rank)

# check the resulting datasets
dim(spam_train)
dim(spam_test)
```

## ========== Question 1.3 ==========
Train a LogisticRegression classifier by using training data. Report the classification accuracy on both the training and test sets. Does your classifier generalise well on unseen data?

``` {r q1.3}
lr_model <- glm(is_spam ~ ., data = spam_train, family = "binomial")
# train set predictions and accuracy
spam_train$spam_prob <- predict(lr_model, type = "response")
spam_train$spam_pred <- ifelse(spam_train$spam_prob > mean(spam_train$is_spam), 1, 0)
(acc_train <- round(mean(spam_train$spam_pred == spam_train$is_spam), 2))
# test set predictions and accuracy
spam_test$spam_prob <- predict(lr_model, newdata = spam_test, type = "response")
spam_test$spam_pred <- ifelse(spam_test$spam_prob > mean(spam_train$is_spam), 1, 0) # use the mean from the train set
(acc_test <- round(mean(spam_test$spam_pred == spam_test$is_spam), 2))
```

The accuracy on the train set is `r acc_train` and the accuracy on the test set is `r acc_test`, these are close, suggesting the model generalises well to new data.

## ========== Question 1.4 ==========
**Print the coefficients for class 1 for the attributes word_freq_hp_binarized and char_freq_$_binarized.**

An encoding error means that `char_freq_$_binarized` appears as `char_freq_._binarized.4` - I tried to sort this out with the `fileEndcoing` and `encoding` options in `read.csv` but couldn't work it out. I will look into this when I have more time.

``` {r q1.4}
(lo_hp <- round(lr_model$coefficients["word_freq_hp_binarized"], 2))
(lo_.4 <- round(lr_model$coefficients["char_freq_._binarized.4"], 2))
```

**Generally, we would expect the string $ to appear in spam, and the string hp to appear in non-spam e-mails, as the data was collected from HP Labs. Do the regression coefficients make sense given that class 1 is spam? Hint: Consider the sigmoid function and how it transforms values into a probability between 0 and 1. Since our attributes are boolean, a positive coefficient can only increase the total sum fed through the sigmoid and thus move the output of the sigmoid towards 1. What can happen if we have continuous, real-valued attributes?**

Interpretation f coefficients:
The log odds of an email being spam changes by `r lo_hp` and `r lo_.4` when "hp" and "\$" are present in the email respectively. I.e. presence of "hp" means the email less likely to categorized as spam, "\$" more likey to be categorized as spam. This makes sense.

Note: I tried to name the variable "lo_$", which was fine using backticks when assigning the name, but couldn't work out how to print this in R markdown without producing errors. 







